{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "print(\"Imports...\")\n",
        "\n",
        "!sudo apt install -y fluidsynth\n",
        "!pip install --upgrade pyfluidsynth\n",
        "!pip install pretty_midi\n",
        "\n",
        "import fluidsynth\n",
        "import glob\n",
        "import itertools\n",
        "import music21\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import pretty_midi\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "from music21 import converter, note, chord\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe-Uw4SGFsDQ",
        "outputId": "dc13db07-ae5c-465d-87c1-604ec5aab11c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fluidsynth is already the newest version (2.1.1-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyfluidsynth in /usr/local/lib/python3.8/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pyfluidsynth) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.8/dist-packages (0.2.9)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.8/dist-packages (from pretty_midi) (1.2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from pretty_midi) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from pretty_midi) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IcNOKkNfFRkh"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "_SAMPLING_RATE = 16000"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pobieramy dataset maestro zawierający utwory MIDI."
      ],
      "metadata": {
        "id": "G4YsbuRaJ7_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path('data/maestro-v3.0.0')\n",
        "if not data_dir.exists():\n",
        "  tf.keras.utils.get_file(\n",
        "      'maestro-v3.0.0-midi.zip',\n",
        "      origin='https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip',\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data',\n",
        "  )"
      ],
      "metadata": {
        "id": "0Xs6I2YOGS1H"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
        "print('Number of files:', len(filenames))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY7uBOZOGaAV",
        "outputId": "50af1136-e762-4495-f2d3-6aca517eaf5c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files: 1276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tworzymy listę list \"notes\", którą zapiszemy do pliku za pomocą biblioteki pickle (to kwestia optymalizacji czasowej, proces obróbki 1276 plików MIDI trwa bardzo dużo czasu, nawet kilkanaście godzin).\n",
        "\n",
        "W przypadku gdy w danym utworze natrafimy na nutę to zapisujemy jej wartość stringową do listy, jeśli natrafimy na akord to zamieniamy go na \"sumę stringową\" nut: np. 'E5+C4+D5'.\n",
        "\n",
        "Zatem nasza wartość notes dla przykładu ma wartość: [ [C4, E3, G#3, E5+C4+D5, ...], [...], [...], ... ], gdzie notes[i] określa listę nut/akordów dla pliku o indeksie 'i' ze zbioru Maestro."
      ],
      "metadata": {
        "id": "JGFfR7j_J_tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notes = []\n",
        "d = filenames[0:500]\n",
        "all = len(d)\n",
        "\n",
        "for count, f in enumerate(d):\n",
        "    n = []\n",
        "    midi = converter.parse(f)\n",
        "    midi_notes = midi.flat.notes\n",
        "\n",
        "    for c, element in enumerate(midi_notes):\n",
        "        if isinstance(element, note.Note):\n",
        "            n.append(str(element.pitch))\n",
        "\n",
        "        elif isinstance(element, chord.Chord):\n",
        "            n.append(\"+\".join(str(n) for n in element.normalOrder))\n",
        "\n",
        "\n",
        "    notes.append(n)\n",
        "    print(f\"f: {count} / {all}\")"
      ],
      "metadata": {
        "id": "turmYxjNICZ0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "W tym i pozostałych przykładach, posługuję się biblioteką pickle do zapisu zawartości zmiennych - przyczyną tego są kwestie pamięci RAM."
      ],
      "metadata": {
        "id": "f9gT4nH4MXXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data/list_of_notes\" , \"wb\") as file:\n",
        "    pickle.dump(notes, file)"
      ],
      "metadata": {
        "id": "u3mYGxuKMP5Q"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalnie postanowiłem ograniczyć się do prawie połowy datasetu Maestro (500 plików). Są to dane zdecydowanie wystarczające na potrzeby tego projektu, szczególnie biorąc pod uwagę, że każdy utwór zawiera w sobie średnio kilka tysięcy elementów (nut oraz akordów)."
      ],
      "metadata": {
        "id": "TTvMvLluLid3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data/list_of_notes_filenames[0_500]\" , \"rb\") as file:\n",
        "    notes = pickle.load(file)\n",
        "\n",
        "print(len(notes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkVWPYDVL9Pt",
        "outputId": "dea7867c-525c-4cb1-a58d-b67adc96f1d3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notes_len = np.array([len(i) for i in notes])\n",
        "min_len = np.min(notes_len)\n",
        "max_len = np.max(notes_len)\n",
        "avg_len = np.average(notes_len)\n",
        "\n",
        "print(min_len, max_len, avg_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZXQDj2AMpE8",
        "outputId": "d143df08-04c6-4096-9d26-f9cbbe3f1071"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "474 15197 4154.682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zauważmy, że liczba unikalnych nut (wraz z akordami) wynosi 1335:"
      ],
      "metadata": {
        "id": "pfUNPvzwR5ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_notes = list(itertools.chain.from_iterable(notes))\n",
        "unique_notes = len(set(all_notes))\n",
        "print(unique_notes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQbLRTGORwXf",
        "outputId": "8e9d4d83-7baa-4ae4-d370-43d12083d421"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tworzymy określenie relacji nuta <-> liczba, chcemy docelowo mieć mechanizm do zmiany nuty na liczbę i odwrotnie."
      ],
      "metadata": {
        "id": "YIFhXNUwSUqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = sorted(set(all_notes))\n",
        "note_to_int = dict((element, idx) for idx, element in enumerate(names))\n",
        "int_to_note = {idx:element for element, idx in note_to_int.items()}\n",
        "\n",
        "assert len(note_to_int) == unique_notes\n",
        "assert len(int_to_note) == unique_notes"
      ],
      "metadata": {
        "id": "O3ObQB5TSO9H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data/note_to_int\" , \"wb\") as file:\n",
        "    pickle.dump(note_to_int, file)\n",
        "\n",
        "with open(\"data/int_to_note\" , \"wb\") as file:\n",
        "    pickle.dump(int_to_note, file)"
      ],
      "metadata": {
        "id": "lnfVVGCKDU-v"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_note_to_int(note):\n",
        "  return note_to_int[note]\n",
        "\n",
        "def map_int_to_note(note):\n",
        "  return int_to_note[note]\n",
        "\n",
        "np_note_to_int = np.vectorize(map_note_to_int)\n",
        "np_int_to_note = np.vectorize(map_int_to_note)"
      ],
      "metadata": {
        "id": "1gBoE8wjSxCC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zamieniamy nuty z naszego wstępnego datasetu na liczby:"
      ],
      "metadata": {
        "id": "_yOtb1T3S2DN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "int_notes = [list(np_note_to_int(np.array(i))) for i in notes]"
      ],
      "metadata": {
        "id": "lgocS4olS1IU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tworzymy interpretację binarną liczbowych nut: dla każdej nuty tworzymy wektor zer oraz jedynki, która jest umiejscowiona na pozycji note_to_int[nuta-1]. Stąd np. dla liczby nutowej 138, wektor będzie miał postać l =  [0, 0, 0, ..., 1, 0, 0, ...], gdzie l[137] = 1."
      ],
      "metadata": {
        "id": "QI-a9giIMwL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_bin(list_int_notes, unique=unique_notes):\n",
        "  result_data = []\n",
        "  for midi in list_int_notes:\n",
        "    temp = []\n",
        "    for i in midi:\n",
        "      h = [0.0] * unique\n",
        "      if i > 0:\n",
        "        h[i-1] = 1.0\n",
        "      else:\n",
        "        h[0] = 1.0\n",
        "      temp.append(h)\n",
        "    result_data.append(temp)\n",
        "  \n",
        "  return result_data"
      ],
      "metadata": {
        "id": "4XboYTZIpZg4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = convert_to_bin(int_notes)"
      ],
      "metadata": {
        "id": "enTx2pczp4Y7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tworzymy zbiór X oraz predykcję (Y), długość każdego podzbioru X ustalamy domyślnie na 20 - daje to sensowne wyniki, sugestię co do wyboru takiej wartości daje sama biblioteka Magenta. Długość każdej podlisty zbioru Y to 1.\n",
        "\n",
        "Przykład podziału na X oraz Y dla nut liczbowych [145, 7, 131, 31, 342, 1231, 99, 1, 131, 55, 41, 442, 14, 15, 16, 99, 245, 16, 19, 204, 99, 131, 3]:\n",
        "\n",
        "```\n",
        "X = [ [145, 7, 131, 31, 342, 1231, 99, 1, 131, 55, 41, 442, 14, 15, 16, 99, 245, 16, 19, 204], [7, 131, 31, 342, 1231, 99, 1, 131, 55, 41, 442, 14, 15, 16, 99, 245, 16, 19, 204, 99], ... ]\n",
        "\n",
        "Y = [ [99], [131], ... ]\n",
        "```\n",
        "\n",
        "Oczywiście postać X i Y jest wcześniej zmapowana do wartości wektorów binarnych.\n",
        "\n",
        "\n",
        "Dodatkowo ustaliłem tutaj, że dla każdego utworu muzycznego ograniczymy się do wartości bliskiej najmniejszego utworu w datasecie - ustaliłem długość każdego jako 400 nut/akordów."
      ],
      "metadata": {
        "id": "IWJmlMpxOQMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(input_array, n_prev = 20):\n",
        "  temp_x = []\n",
        "  temp_y = []\n",
        "  for midi in input_array:\n",
        "    temp_x.append([midi[i:i+n_prev] for i in range(len(midi) - n_prev) if i+n_prev < 400])\n",
        "    temp_y.append([midi[i+n_prev] for i in range(len(midi) - n_prev) if i+n_prev < 400])\n",
        "\n",
        "  temp_x = list(itertools.chain.from_iterable(temp_x))\n",
        "  temp_y = list(itertools.chain.from_iterable(temp_y))\n",
        "\n",
        "  return np.array(temp_x), np.array(temp_y)"
      ],
      "metadata": {
        "id": "36Y5SexUHDCF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = generate_dataset(data)"
      ],
      "metadata": {
        "id": "en3Ldml_vPYV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, shuffle=False)"
      ],
      "metadata": {
        "id": "idDuX1uBBDTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data/x_train\" , \"wb\") as file:\n",
        "    pickle.dump(x_train, file)\n",
        "\n",
        "with open(\"data/x_test\" , \"wb\") as file:\n",
        "    pickle.dump(x_test, file)\n",
        "\n",
        "with open(\"data/y_train\" , \"wb\") as file:\n",
        "    pickle.dump(y_train, file)\n",
        "\n",
        "with open(\"data/y_test\" , \"wb\") as file:\n",
        "    pickle.dump(y_test, file)"
      ],
      "metadata": {
        "id": "xWFmeSkwI6QX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}